{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 3352 Biological Networks, Spring 2022, Prof. Clauset\n",
    "Submit here: https://canvas.colorado.edu/courses/80370"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4 : Predicting missing node attributes in networks\n",
    "\n",
    "***\n",
    "\n",
    "**Name**: Giuliano Costa\n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Canvas by **11:55pm on Friday, February 11th**. Your solutions to non-programming questions should be done in Markdown directly below the associated question. Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own** (see syllabus for detailed guidance). There are 90 points total, and 25 pts extra credit.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Unless a url is given for a data set, you will find the required data on the course Canvas.\n",
    "- If you're not familiar with typesetting math directly in Markdown, you may do your work on paper first and then typeset it later. This [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) provides helpful guidance for writing math in Markdown. \n",
    "- It is **unhelpful** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code.\n",
    "\n",
    "***\n",
    "* [Documentation for networkx](https://networkx.github.io/documentation/stable/)\n",
    "\n",
    "[//]: <> (Documentation for igraph Python https://igraph.org/python/ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem 1 : Label me this, label me that (85 pts total)\n",
    "\n",
    "In this problem, you will implement and systematically evaluate the `local smoothing` prediction algorithm. We'll build up this numerical experiment in stages. First, you'll implement the `baseline` predictor, then the `local smoothing` predictor. After that, you'll construct a *good* test of the `local smoothing` algorithm for a single choice of a _missingness function_ $f$. And finally, you'll write a wrapper around this function to explore how performance varies as a function of $f$.\n",
    "\n",
    "For the last two steps, we'll use a real-world network derived from the genes of the human malaria parasite _P. falciparum_. These genes are located in one of nine highly variable regions (HVRs) in the DBLa domain of the parasite's var protein. In this network, nodes are antigen *genes* of the parasite and two nodes are connected if they contain evidence of past non-homologous *recombination* (basically, if they share a long subsequence). The node metadata represents a biologically-relevant classification scheme of the nodes.\n",
    "* Visit the [Index of Complex Networks](https://icon.colorado.edu/) and obtain the `HVR_5` network and `metadata_CysPoLV` node attribute files for the ICON entry _Malaria var DBLa HVR networks_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1-A (10 pts) Malaria gene recombination network\n",
    "\n",
    "To warm up, load both the *HVR_5* network and treat it as a simple graph (edges unweighted and undirected; no multi-edges; no self-loops), and the *metadata_CysPoLV* file. Then calculate and report the following.\n",
    "* number of nodes $n$\n",
    "* (undirected) edges $m$\n",
    "* mean degree $\\langle k \\rangle$\n",
    "* clustering coefficient $C$\n",
    "* mean geodesic distance $\\langle \\ell \\rangle$\n",
    "* a `ridiculogram` of the network, using the provided `drawGz()` function\n",
    "* a `bar` plot showing the attribute frequencies in the `metadata` file\n",
    "\n",
    "Note: In the code box below, the preamble takes care of the tricky part of correctly aligning the network data with the node metadata, so that you can focus on the analysis parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawGz(G,z):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    # This function draws G with node labels from partition z\n",
    "    #\n",
    "    # input  : G is a networkx graph\n",
    "    #        : z is a dictionary of group labels for G's nodes\n",
    "    # output : a ridiculogram plot of G\n",
    "    # \n",
    "    # WARNING: function is optimistic: assumes inputs are properly formatted\n",
    "\n",
    "    colors = ['#d61111','#11c6d6','#d67711','#11d646','#1b11d6','#d611cc'] # map node labels to colors (for the visualization)\n",
    "\n",
    "    node_colors = []\n",
    "    for i in G.nodes():\n",
    "        node_colors.append(colors[int(z[i])-1])\n",
    "    nsize  = 600\n",
    "    flabel = True\n",
    "\n",
    "    if G.order() > 50:\n",
    "        nsize  = 50\n",
    "        flabel = False\n",
    "        \n",
    "    nx.draw_networkx(G,with_labels=flabel,node_size=nsize,width=2,node_color=node_colors) # draw it pretty\n",
    "    limits=plt.axis('off')                                      # turn off axes\n",
    "    plt.show() \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading the network file  : ./data/HVR_5.txt\n",
      "reading the metadata file : ./data/metadata_CysPoLV.txt\n",
      "\n",
      "number of nodes, n  = 298\n",
      "number of edges, m  = 2684\n",
      "mean degree,    <k> = 18.01\n",
      "clustering coefficient, C     =  0.36\n",
      "mean geodesic distance, <ell> =  2.92\n"
     ]
    }
   ],
   "source": [
    "# this data set is from :\n",
    "# D. B. Larremore et al., \"A network approach to analyzing highly recombinant malaria parasite genes.\"\n",
    "#                          PLOS Computational Biology 9(10), e1003268 (2013).\n",
    "fname1 = './data/HVR_5.txt'\n",
    "fname2 = './data/metadata_CysPoLV.txt'\n",
    "\n",
    "# read in the network file (an edge list)\n",
    "print(f'reading the network file  : {fname1}')\n",
    "G = nx.read_edgelist('./' + fname1, delimiter=',', nodetype=int)  # import simple graph, index nodes by integers (not strings)\n",
    "\n",
    "# read in the node metadata (note: there are more metadata values here than nodes in G)\n",
    "print(f'reading the metadata file : {fname2}\\n')\n",
    "f = open('./' + fname2,'r')\n",
    "labels = []\n",
    "for line in f:\n",
    "    labels.append(int(line.rstrip('\\n'))) # strip the \\n and convert label to an int\n",
    "f.close() \n",
    "\n",
    "# for each node i in G, add (j: j's label) to a dictionary z\n",
    "z = {}\n",
    "for i in range(0,len(labels)):\n",
    "    if i+1 in G.nodes():\n",
    "        z[i+1] = labels[i] \n",
    "    \n",
    "####################################\n",
    "##### do not modify above here #####\n",
    "\n",
    "k = []\n",
    "for i in G.degree():\n",
    "    k.append( i[1])\n",
    "    \n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "kmean = np.sum(k) / n\n",
    "\n",
    "C = nx.transitivity(G)\n",
    "ellmean = nx.average_shortest_path_length(G)\n",
    "\n",
    "\n",
    "##### do not modify below here #####\n",
    "####################################\n",
    "\n",
    "print(f'number of nodes, n  = {n}')\n",
    "print(f'number of edges, m  = {m}')\n",
    "print(f'mean degree,    <k> = %5.2f' % kmean)\n",
    "print(f'clustering coefficient, C     = %5.2f' % C)\n",
    "print(f'mean geodesic distance, <ell> = %5.2f' % ellmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1-B (10 pts) : the baseline\n",
    "\n",
    "* Write the function `predictLabel_baseline(x)` to implement the `baseline` node attribute predictor given in Lecture Notes 4.\n",
    "  * It takes as input `x`, a dictionary of observed labels (node i: label of i), within which a $-1$ indicates a missing label.\n",
    "  * It returns as output, the result of the baseline predictor.\n",
    "* Then, write code in the cell below that to\n",
    "  * apply your predictor to each of the nodes in the $G_\\circ$ given below,\n",
    "  * for each prediction, print a statement of the form `node 1 : -1 -> 2 (baseline)` that gives the node a prediction was made for, its observed `x` value and its predicted value, and then\n",
    "  * store the final labels (non-missing observed + predictions) in a dictionary `xp`.\n",
    "\n",
    "Note: the preamble below includes the graph `Go`, and a given labeling `x`, and will display both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLabel_baseline(x):\n",
    "    # input:  x, dict of observed labels\n",
    "    # output: baseline predictor, Uniform(\\vec{x}-\\emptyset)\n",
    "    \n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "seed = # your MMYY birthday here\n",
    "rnd.seed(seed)\n",
    "\n",
    "# a small network to test your baseline predictor\n",
    "Go = nx.Graph([(1,2),(1,3),(1,4),(1,5),(1,6)])\n",
    "\n",
    "# and its observed node labels x, as a dictionary\n",
    "x = {1: -1, 2: 1, 3: 2, 4: 2, 5: -1, 6: 3}\n",
    "\n",
    "# to start, display the observed labels and draw G with them\n",
    "print(f'initial node labels and network:')\n",
    "for i in x:\n",
    "    print(f'node {i}, label {x[i]}')\n",
    "drawGz(Go,x)\n",
    "\n",
    "xp = {} # put your node labels, after predictions, here (as a dictionary)\n",
    "print(f'\\napplying baseline predictor to')\n",
    "\n",
    "####################################\n",
    "##### do not modify above here #####\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE\n",
    "\n",
    "\n",
    "\n",
    "##### do not modify above here #####\n",
    "####################################\n",
    "print(f'\\nfinal node labels and network:')\n",
    "for i in xp:\n",
    "    print(f'node {i}, label {xp[i]}')\n",
    "drawGz(Go,xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1-C (15 pts) : local smoothing\n",
    "\n",
    "* Now write a function `predictLabel_local(G,i,x,flag)` that implements the `local smoothing` node attribute predictor for categorical variables given in Lecture Notes 4.\n",
    "  * It takes as input the graph `G`, a node index `i`, and a dictionary of observed labels `x`, as before.\n",
    "  * As in Problem Set 2, `flag` is a binary variable that toggles whether for each prediction, it prints a statement of the form `node 1 : -1 -> 2 ([method])`, where `method` is either `smoothing` or `baseline`, depending on which predictor was applied.\n",
    "\n",
    "* Then,\n",
    "  * apply your predictor (with `flag=1`) to each of the nodes in the $G_\\circ$ given below, and then\n",
    "  * store the final labels (non-missing observed + predictions) in a dictionary `xp`.\n",
    "\n",
    "Hint 1: Don't forget that the `local smoothing` predictor should default to the `baseline` predictor in the event that all of a node's neighbors are missing their labels.\n",
    "\n",
    "Hint 2: To avoid having the output of an early prediction influence the output of a later prediction, for each node $i$, use the `xp` variable to store both the output of any prediction, or the observed label (if no prediction is made). That is, make your predictions *synchronously*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLabel_local(G,i,x,flag):\n",
    "    # input:  G, simple networkx graph\n",
    "    #         i, a node in G whose label we will predict\n",
    "    #         x, dict of observed labels for G\n",
    "    #         flag, binary value\n",
    "    # output: local smoothing predictor output for i\n",
    "    #         a print statement (see instructions) if flag=1\n",
    "    \n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "seed = # your MMYY birthday here\n",
    "rnd.seed(seed)\n",
    "\n",
    "# a graph and its observed node labels, to start\n",
    "Go = nx.Graph([(1,2),(1,3),(1,4),(1,5),(1,6)])\n",
    "x  = {1: -1, 2: 1, 3: 2, 4: 3, 5: -1, 6: 2}\n",
    "\n",
    "# to start, display the observed labels and draw G with them\n",
    "print(f'initial node labels and network:')\n",
    "for i in x:\n",
    "    print(f'node {i}, label {x[i]}')\n",
    "drawGz(Go,x)\n",
    "\n",
    "xp = {} # put your node labels, after predictions, here (as a dictionary)\n",
    "print(f'\\napplying baseline predictor to')\n",
    "\n",
    "####################################\n",
    "##### do not modify above here #####\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE\n",
    "\n",
    "\n",
    "\n",
    "##### do not modify above here #####\n",
    "####################################\n",
    "print(f'\\nfinal node labels and network:')\n",
    "for i in xp:\n",
    "    print(f'node {i}, label {xp[i]}')\n",
    "drawGz(Go,xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1-D (35 pts) : missingness\n",
    "\n",
    "Now we get to play with malaria gene data. Let the missingness function $f$ be one that selects a uniformly random _fraction_ $\\alpha\\in(0,1)$ of attributes to observe. And, define the performance measure to be the `accuracy (ACC)`.\n",
    "\n",
    "Because $f$ is a stochastic function, the accuracy we calculate will be a random variable. Hence, just like in Problem Set 3, we will need to average the accuracy over several _repetitions_ to get a good estimate.\n",
    "\n",
    "* Write a function `compute_ACC_onG(G,x,alpha)` that computes the ACC for applying the `local smoothing` predictor to an instance of $G$ in which we observe each node's attribute with probability $\\alpha$. This function takes as input the network `G`, the actual node labels `x`, and the value $\\alpha$. It should then construct an observed set of labels `xo`, produce a set of predicted labels `xp`, and then return the ACC for those predictions.\n",
    "* In the cell below that, write a wrapper around your function that computes the ACCs over `nrep=10` repetitions, each with $\\alpha=0.8$.\n",
    "* Report both\n",
    "  * the list of individual ACCs (one per rep) and\n",
    "  * their average over all reps.\n",
    "* Finally, in the discussion box below that, briefly comment about how well `local smoothing` does at this task, in light of any class balance issues.\n",
    "\n",
    "Hint 1: I used a $c \\times c$ numpy array, where $c$ is the number of unique labels in `x`, to construct the confusion matrix, and then used the `np.trace()` and `.sum()` functions to get the ACC.\n",
    "\n",
    "Hint 2: You can check that your code is about right by trying a few different values of $\\alpha$. When I ran it with $\\alpha=0.05$, I found ACC $\\approx0.50$, and with $\\alpha=0.95$, I found ACC $\\approx0.70$. This makes sense that ACC should increase with $\\alpha$, since at higher values, we're making fewer predictions and have more observed labels to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ACC_onG(G,x,alpha):\n",
    "    # input : G, a networkx simple graph\n",
    "    #         x, (dict) actual labels of nodes in G\n",
    "    #         alpha, (scalar) fraction of labels to observe\n",
    "    # output: ACC of local smoothing predictor\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "seed = # your MMYY birthday here\n",
    "rnd.seed(seed)\n",
    "\n",
    "nreps  = 10   # number of repetitions to average over\n",
    "alpha  = 0.80  # fraction of labels to observe\n",
    "ACCs   = []   # list of nrep values of ACC\n",
    "\n",
    "##### do not modify above here #####\n",
    "####################################\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "    \n",
    "####################################\n",
    "##### do not modify below here #####    \n",
    "print(f'[ n={n} | reps={nreps} ] <ACC> = %6.3f' % np.mean(ACCs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your discussion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1-E (20 pts) putting it all together\n",
    "\n",
    "Using the code you wrote for `Problem 1-D`, write a simple wrapper around it that performs the full numerical experiment to investigate how the `local smoothing` predictor performs (mean ACC over reps) as a function of how much of the network is labeled (alpha).\n",
    "\n",
    "* Write the wrapper around your `Problem 1-D` code to measure how the mean ACC varies a function of $\\alpha$ on the malaria gene network.\n",
    "\n",
    "* Produce a single `plot` showing this function, for $\\alpha=\\{0.1, 0.3, 0.5, 0.7, 0.9\\}$ and `nreps=100` (try a smaller number to see how much roughness you're smoothing over).\n",
    "* (*Extra credit 5pts*: use at least 10 evenly-spaced increments of $\\alpha$ between 0 and 1.)\n",
    "\n",
    "* Briefly discuss what you see about how the ACC varies with $\\alpha$. What trend do you see? Does it go in the direction you would expect? Why is the worst accuracy better than $1/c$, where $c$ is the number of unique labels? Try to give some intuition as to why this behavior makes sense given what we know about how `local smoothing` works and the mean degree $\\langle k \\rangle$ of the malaria gene network.\n",
    "\n",
    "Hint: As in PS3, a key part of such a numerical experiment is how you store the intermediate results. For each choice of $\\alpha$, the core code from `Problem 1-D` will produce a single pair that you can plot $(\\alpha,\\textrm{ACC})$, but you'll need to store these pairs of values while the rest are being calculated. It may be useful to separate the code for the experiment from the code for the visualization, so that you can tinker with the latter without having to re-run the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR NUMERICAL EXPERIMENT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PLOTTING CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your discussion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "\n",
    "## Problem 2 : Reading the literature (*10 pts extra credit*)\n",
    "\n",
    "Choose a paper from the [Supplemental Reading list on the external course webpage](http://tuvalu.santafe.edu/~aaronc/courses/3352/). Read the paper (the whole paper, not just the abstract). Think about what it says. Then, write 1-3 sentences for each of the following questions in a way that clearly summarizes the work, and its context.\n",
    "* What was the research question?\n",
    "* What was the approach the authors took to answer that question?\n",
    "* What did they do well?\n",
    "* What could they have done better?\n",
    "* What extensions can you envision?\n",
    "\n",
    "\n",
    "Do not copy any text from the paper itself; write your own summary, in your own words in Markdown in the corresponding box below. Be sure to answer each of the five questions. The amount of extra credit will depend on the accuracy and thoughtfulness of your answers.\n",
    "\n",
    "Hint: This is a good way to generate some ideas for your class project. Also, even if you don't understand everything in the paper, that's okay. Do your best to summarize what you did understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *What paper did you choose?*<br/>\n",
    "Give the Authors, Title, Publication Venue, Year\n",
    "<br/>\n",
    "\n",
    "* *What was the research question?*<br/>\n",
    "Your answer here\n",
    "<br/>\n",
    "\n",
    "* *What was the approach the authors took to answer that question?*<br/>\n",
    "Your answer here\n",
    "<br/>\n",
    "\n",
    "* *What did they do well?*<br/>\n",
    "Your answer here\n",
    "<br/>\n",
    "\n",
    "* *What could they have done better?*<br/>\n",
    "Your answer here\n",
    "<br/>\n",
    "\n",
    "* *What extensions can you envision?*<br/>\n",
    "Your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d8eb5f0b2d1a671b125662acba05eb56e47a909e2cbb43cb4ed44d16297229b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
